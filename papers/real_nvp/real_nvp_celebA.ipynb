{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.utils.parametrizations as parametrizations\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from framework import BaseCouplingLayer\n",
    "from framework import BaseChunker\n",
    "from framework import NormalizingFlow\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def apply_weight_norm(module):\n",
    "    \"\"\"\n",
    "    Applies weight normalization to all Conv2d and Linear layers in a given module.\n",
    "    \n",
    "    Args:\n",
    "        module (nn.Module): The PyTorch module to which weight normalization will be applied.\n",
    "    \"\"\"\n",
    "    for name, layer in module.named_children():\n",
    "        if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
    "            setattr(module, name, parametrizations.weight_norm(layer))\n",
    "        # Recursively apply weight normalization to nested modules\n",
    "        if len(list(layer.children())) > 0:\n",
    "            apply_weight_norm(layer)\n",
    "            \n",
    "\n",
    "def get_scaling_factor_histogram(model):\n",
    "    scaling_factors = []\n",
    "    \n",
    "    # Traverse the model to find all RealNVPCouplingFunction layers\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, SequentialCouplingLayer):\n",
    "            for sub_layer in layer.layers:\n",
    "                if isinstance(sub_layer, AffineCouplingLayer):\n",
    "                    if isinstance(sub_layer.coupling_function, RealNVPCouplingFunction):\n",
    "                        # Extract the scaling factor\n",
    "                        scaling_factors.append(sub_layer.coupling_function.scaling_factor.item())\n",
    "    \n",
    "    return scaling_factors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SpatialCheckerboardChunker(BaseChunker):\n",
    "    def __init__(self, permute=True):\n",
    "        super(SpatialCheckerboardChunker, self).__init__()\n",
    "        self.permute = permute\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Split the input tensor into two chunks based on a spatial checkerboard pattern.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Tensor, Tensor]: Tuple of two tensors split based on the checkerboard pattern.\n",
    "        \"\"\"\n",
    "        x1 = torch.zeros(x.size(0), x.size(1), x.size(2), x.size(3), device=x.device, dtype=x.dtype)\n",
    "        x2 = torch.zeros(x.size(0), x.size(1), x.size(2), x.size(3), device=x.device, dtype=x.dtype)\n",
    "        x1[:, :, ::2, 1::2] = x[:, :, ::2, 1::2]\n",
    "        x1[:, :, 1::2, ::2] = x[:, :, 1::2, ::2]\n",
    "        x2[:, :, ::2, ::2] = x[:, :, ::2, ::2]\n",
    "        x2[:, :, 1::2, 1::2] = x[:, :, 1::2, 1::2]\n",
    "\n",
    "        if not self.permute:\n",
    "            return x2, x1\n",
    "        else:\n",
    "            return x1, x2\n",
    "    \n",
    "    def invert(self, y1, y2):\n",
    "        \"\"\"\n",
    "        Combine two tensors into one based on a checkerboard pattern.\n",
    "        \n",
    "        Args:\n",
    "            y1 (Tensor): First tensor.\n",
    "            y2 (Tensor): Second tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Combined tensor.\n",
    "        \"\"\"\n",
    "        x = torch.zeros(y1.size(0), y1.size(1), y1.size(2), y1.size(3), device=y1.device, dtype=y1.dtype)\n",
    "\n",
    "        if not self.permute:\n",
    "            x[:, :, ::2, 1::2] = y2[:, :, ::2, 1::2]\n",
    "            x[:, :, 1::2, ::2] = y2[:, :, 1::2, ::2]\n",
    "            x[:, :, ::2, ::2] = y1[:, :, ::2, ::2]\n",
    "            x[:, :, 1::2, 1::2] = y1[:, :, 1::2, 1::2]\n",
    "        else:\n",
    "            x[:, :, ::2, 1::2] = y1[:, :, ::2, 1::2]\n",
    "            x[:, :, 1::2, ::2] = y1[:, :, 1::2, ::2]\n",
    "            x[:, :, ::2, ::2] = y2[:, :, ::2, ::2]\n",
    "            x[:, :, 1::2, 1::2] = y2[:, :, 1::2, 1::2]\n",
    "\n",
    "        return x\n",
    "\n",
    "class ChannelWiseChunker(BaseChunker):\n",
    "    def __init__(self, permute=False):\n",
    "        super(ChannelWiseChunker, self).__init__()\n",
    "        self.permute = permute\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Split the input tensor into two halves along the channel dimension.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Tensor, Tensor]: Tuple of two tensors split along the channel dimension.\n",
    "        \"\"\"\n",
    "        x1, x2 = x.chunk(2, dim=1)\n",
    "        if self.permute:\n",
    "            return x2, x1\n",
    "        else:\n",
    "            return x1, x2\n",
    "    \n",
    "    def invert(self, y1, y2):\n",
    "        \"\"\"\n",
    "        Combine two tensors into one by concatenating along the channel dimension.\n",
    "        \n",
    "        Args:\n",
    "            y1 (Tensor): First tensor.\n",
    "            y2 (Tensor): Second tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Combined tensor.\n",
    "        \"\"\"\n",
    "        if self.permute:\n",
    "            return torch.cat([y2, y1], dim=1)\n",
    "        else:\n",
    "            return torch.cat([y1, y2], dim=1)\n",
    "        \n",
    "        \n",
    "class SqueezingCouplingLayer(BaseCouplingLayer):\n",
    "    def __init__(self, factor=2):\n",
    "        super(SqueezingCouplingLayer, self).__init__()\n",
    "        self.factor = factor\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "        x = x.view(b, c, h//self.factor, self.factor, w//self.factor, self.factor).permute(0, 1, 3, 5, 2, 4).contiguous()\n",
    "        return x.view(b, c*self.factor*self.factor, h//self.factor, w//self.factor), torch.zeros(x.size(0), device=x.device)\n",
    "\n",
    "    def inverse(self, y):\n",
    "        return self.invert(y)\n",
    "    \n",
    "    def invert(self, y):\n",
    "        b, c, h, w = y.size()\n",
    "        y = y.view(b, c//(self.factor*self.factor), self.factor, self.factor, h, w).permute(0, 1, 4, 2, 5, 3).contiguous()\n",
    "        return y.view(b, c//(self.factor*self.factor), h*self.factor, w*self.factor)\n",
    "    \n",
    "    def log_det_jacobian(self, x):\n",
    "        return torch.zeros(x.size(0), device=x.device)\n",
    "    \n",
    "\n",
    "class SequentialCouplingLayer(BaseCouplingLayer):\n",
    "    def __init__(self, layers):\n",
    "        super(SequentialCouplingLayer, self).__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        log_det_jac = torch.zeros(x.size(0), device=x.device)\n",
    "        for layer in self.layers:\n",
    "            x, ldj = layer(x)\n",
    "            log_det_jac += ldj\n",
    "        return x, log_det_jac\n",
    "    \n",
    "    def inverse(self, y):\n",
    "        x = y\n",
    "        for layer in reversed(self.layers):\n",
    "            x = layer.inverse(x)\n",
    "        return x\n",
    "    \n",
    "    def log_det_jacobian(self, x):\n",
    "        _, ldj = self(x)\n",
    "        return ldj\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, batch_norm=False):\n",
    "        super(ResBlock, self).__init__()\n",
    "        if batch_norm:\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.LeakyReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.LeakyReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "            )\n",
    "        \n",
    "        if in_channels != out_channels:\n",
    "            self.skip = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        else:\n",
    "            self.skip = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        if self.skip is not None:\n",
    "            x = self.skip(x)\n",
    "        return out + x\n",
    "\n",
    "class SeriesResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_blocks, batch_norm=False):\n",
    "        super(SeriesResNetBlock, self).__init__()\n",
    "        \n",
    "        self.res_blocks = nn.ModuleList()\n",
    "        self.conv_block = nn.Conv2d(in_channels, hidden_channels, kernel_size=3, padding=1, bias=True)\n",
    "        for _ in range(num_blocks):\n",
    "            self.res_blocks.append(ResBlock(in_channels, hidden_channels, batch_norm))\n",
    "            in_channels = hidden_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        temp_x = x\n",
    "        for block in self.res_blocks:\n",
    "            x = block(x)\n",
    "        return x + self.conv_block(temp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormCouplingLayer(BaseCouplingLayer):\n",
    "    def __init__(self, num_features, momentum=0.1, eps=1e-5):\n",
    "        super(BatchNormCouplingLayer, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.momentum = momentum\n",
    "        self.eps = eps\n",
    "        \n",
    "        # These buffers store the running averages of mean and variance\n",
    "        self.register_buffer('avg_mean', torch.zeros(num_features))\n",
    "        self.register_buffer('avg_var', torch.ones(num_features))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            # Calculate mean and variance along the batch, height, and width dimensions\n",
    "            batch_mean = x.mean(dim=(0, 2, 3))  # mean over batch, height, width\n",
    "            batch_var = x.var(dim=(0, 2, 3), unbiased=False)  # var over batch, height, width\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # Update running mean and variance (moving averages)\n",
    "                self.avg_mean = self.momentum * self.avg_mean + (1 - self.momentum) * batch_mean\n",
    "                self.avg_var = self.momentum * self.avg_var + (1 - self.momentum) * batch_var\n",
    "        else:\n",
    "            # Use running averages during evaluation\n",
    "            batch_mean = self.avg_mean\n",
    "            batch_var = self.avg_var\n",
    "        \n",
    "        # Normalize the input using the current batch statistics or running averages\n",
    "        mean = batch_mean.view(1, -1, 1, 1)\n",
    "        var = batch_var.view(1, -1, 1, 1)\n",
    "        normalized = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        \n",
    "        # Calculate the log determinant of the Jacobian\n",
    "        lf = x.numel() / x.size(0)\n",
    "        log_det = -0.5 * torch.sum(torch.log(var + self.eps)).repeat(x.size(0)) * lf / x.size(1)\n",
    "        \n",
    "        return normalized, log_det\n",
    "\n",
    "    def inverse(self, x):\n",
    "        # Inverse of the normalization using running averages\n",
    "        mean = self.avg_mean.view(1, -1, 1, 1)\n",
    "        var = self.avg_var.view(1, -1, 1, 1)\n",
    "        \n",
    "        # De-normalize the input\n",
    "        out = x * torch.sqrt(var + self.eps) + mean\n",
    "        return out\n",
    "    \n",
    "    def log_det_jacobian(self, x):\n",
    "        var = self.avg_var.view(1, -1, 1, 1)\n",
    "        lf = x.numel() / x.size(0)\n",
    "        log_det = -0.5 * torch.sum(torch.log(var + self.eps)).repeat(x.size(0)) * lf / x.size(1)\n",
    "        return log_det\n",
    "        \n",
    "class AffineCouplingLayer(BaseCouplingLayer):\n",
    "    def __init__(self, coupling_function, chunker, should_mask = True):\n",
    "        super(AffineCouplingLayer, self).__init__()\n",
    "        self.coupling_function = coupling_function\n",
    "        self.chunker = chunker\n",
    "        self.should_mask = should_mask\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1, x2 = self.chunker(x)\n",
    "\n",
    "        scale, shift = self.coupling_function(x1).chunk(2, dim=1)\n",
    "        y1 = x1\n",
    "        y2 = x2*torch.exp(scale) + shift\n",
    "        \n",
    "        if self.should_mask:\n",
    "            _, masked_scale = self.chunker(scale)\n",
    "        else :\n",
    "            masked_scale = scale\n",
    "        return self.chunker.invert(y1, y2), masked_scale.view(x.size(0), -1).sum(dim=1)\n",
    "    \n",
    "    def inverse(self, y):\n",
    "        y1, y2 = self.chunker(y)\n",
    "        scale, shift = self.coupling_function(y1).chunk(2, dim=1)\n",
    "        x1 = y1\n",
    "        x2 = (y2 - shift)*torch.exp(-scale)\n",
    "        return self.chunker.invert(x1, x2)\n",
    "    \n",
    "    def log_det_jacobian(self, x):\n",
    "        x1, x2 = self.chunker(x)\n",
    "        scale, _ = self.coupling_function(x1).chunk(2, dim=1)\n",
    "        if self.should_mask:\n",
    "            _, masked_scale = self.chunker(scale)\n",
    "        else :\n",
    "            masked_scale = scale\n",
    "        return masked_scale.view(x.size(0), -1).sum(dim=1)\n",
    "\n",
    "class RealNVPCouplingFunction(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_blocks, batch_norm=False):\n",
    "        super(RealNVPCouplingFunction, self).__init__()\n",
    "        self.blocks = nn.ModuleList()\n",
    "        temp_in_channels = in_channels\n",
    "        for _ in range(num_blocks):\n",
    "            self.blocks.append(SeriesResNetBlock(in_channels, hidden_channels, num_blocks, batch_norm))\n",
    "            self.blocks.append(nn.LeakyReLU(inplace=True))\n",
    "            in_channels = hidden_channels   \n",
    "        \n",
    "        self.conv = nn.Conv2d(hidden_channels, 2*temp_in_channels, kernel_size=3, padding=1, bias=True)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        self.scaling_factor = nn.Parameter(torch.tensor(0.1, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        scale, shift = x.chunk(2, dim=1)\n",
    "        \n",
    "        scale = self.scaling_factor * self.tanh(scale)\n",
    "        scale = torch.clamp(scale, min=-5.0, max=5.0)\n",
    "        \n",
    "        return torch.cat((scale, shift), dim=1)\n",
    "\n",
    "class RealNVPLayer(BaseCouplingLayer):\n",
    "    def __init__(self, in_channels, hidden_channels, num_blocks, batch_norm=False):\n",
    "        super(RealNVPLayer, self).__init__()\n",
    "        self.first_part = SequentialCouplingLayer(( AffineCouplingLayer(RealNVPCouplingFunction(in_channels, hidden_channels, num_blocks, batch_norm), SpatialCheckerboardChunker(permute=True)),\n",
    "                                                    BatchNormCouplingLayer(in_channels),\n",
    "                                                    AffineCouplingLayer(RealNVPCouplingFunction(in_channels, hidden_channels, num_blocks, batch_norm), SpatialCheckerboardChunker(permute=False)),\n",
    "                                                    BatchNormCouplingLayer(in_channels),\n",
    "                                                    AffineCouplingLayer(RealNVPCouplingFunction(in_channels, hidden_channels, num_blocks, batch_norm), SpatialCheckerboardChunker(permute=True)),\n",
    "                                                    BatchNormCouplingLayer(in_channels)\n",
    "                                                    ))\n",
    "        self.squeeze = SqueezingCouplingLayer()\n",
    "        self.second_part = SequentialCouplingLayer((AffineCouplingLayer(RealNVPCouplingFunction(in_channels*2, hidden_channels, num_blocks, batch_norm), ChannelWiseChunker(permute=False)),\n",
    "                                                    BatchNormCouplingLayer(in_channels*4),\n",
    "                                                    AffineCouplingLayer(RealNVPCouplingFunction(in_channels*2, hidden_channels, num_blocks, batch_norm), ChannelWiseChunker(permute=True)),\n",
    "                                                    BatchNormCouplingLayer(in_channels*4),\n",
    "                                                    AffineCouplingLayer(RealNVPCouplingFunction(in_channels*2, hidden_channels, num_blocks, batch_norm), ChannelWiseChunker(permute=False)),\n",
    "                                                    BatchNormCouplingLayer(in_channels*4)\n",
    "                                                   ))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, ldj1 = self.first_part(x)\n",
    "        x, ldj2 = self.squeeze(x)\n",
    "        x, ldj3 = self.second_part(x)\n",
    "        return x, ldj1 + ldj2 + ldj3\n",
    "    \n",
    "    def inverse(self, y):\n",
    "        x = y\n",
    "        x = self.second_part.inverse(x)\n",
    "        x = self.squeeze.inverse(x)\n",
    "        x = self.first_part.inverse(x)\n",
    "        return x\n",
    "    \n",
    "    def log_det_jacobian(self, x):\n",
    "        _, ldj = self(x)\n",
    "        return ldj\n",
    "    \n",
    "class SoftLogCouplingLayer(BaseCouplingLayer):\n",
    "    def __init__(self, tau=100):\n",
    "        super(SoftLogCouplingLayer, self).__init__()\n",
    "        self.tau = tau\n",
    "    \n",
    "    def forward(self, x):\n",
    "        abs_x = torch.abs(x)\n",
    "        uz = torch.where(abs_x >= self.tau,\n",
    "                         torch.log1p(abs_x - self.tau) + self.tau,\n",
    "                         abs_x)\n",
    "        \n",
    "        ldj_uz = torch.where(abs_x >= self.tau,\n",
    "                                torch.log1p(abs_x - self.tau),\n",
    "                                0)\n",
    "        z = uz * torch.sign(x)\n",
    "        log_det_jacobian = -torch.sum(ldj_uz.view(x.size(0), -1), dim=1)\n",
    "        \n",
    "        return z, log_det_jacobian\n",
    "    \n",
    "    def inverse(self, z):\n",
    "        abs_z = torch.abs(z)\n",
    "        x = torch.where(abs_z >= self.tau,\n",
    "                        torch.expm1(abs_z - self.tau) + self.tau,\n",
    "                        abs_z)*torch.sign(z)\n",
    "        return x\n",
    "    \n",
    "    def log_det_jacobian(self, x):\n",
    "        abs_x = torch.abs(x)\n",
    "        ldj_uz = torch.where(abs_x >= self.tau,\n",
    "                                torch.log1p(abs_x - self.tau),\n",
    "                                0)\n",
    "        return -torch.sum(ldj_uz.view(x.size(0), -1), dim=1)\n",
    "\n",
    "class LogitCouplingLayer(BaseCouplingLayer):\n",
    "    def __init__(self, alpha=0.05):\n",
    "        super(LogitCouplingLayer, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.logit = torch.logit\n",
    "        self.lalpha = torch.log(torch.tensor(1-alpha))\n",
    "\n",
    "    def forward(self, x):\n",
    "        xp = self.alpha + (1-self.alpha)*x\n",
    "        z = self.logit(xp)\n",
    "        \n",
    "        lf = x.numel()/x.size(0)\n",
    "        \n",
    "        ldj = torch.sum(-torch.log(xp*(1-xp)).view(x.size(0), -1), dim=1) + lf*self.lalpha\n",
    "        return z, ldj\n",
    "    \n",
    "    def inverse(self, z):\n",
    "        xp = torch.sigmoid(z)\n",
    "        x = (xp - self.alpha)/(1-self.alpha)\n",
    "        return x\n",
    "    \n",
    "    def log_det_jacobian(self, x):\n",
    "        xp = self.alpha + (1-self.alpha)*x\n",
    "        lf = x.numel()/x.size(0)\n",
    "        ldj = torch.sum(-torch.log(xp*(1-xp)).view(x.size(0), -1), dim=1) + lf*self.lalpha\n",
    "        return ldj\n",
    "    \n",
    "class MultiScaleRealNVP(NormalizingFlow):\n",
    "    def __init__(self, in_size, in_channels, hidden_dim, num_blocks, latent_distribution, device=None, batch_norm=False):\n",
    "        assert in_size % 2 == 0, \"Input size must be divisible by 2\"\n",
    "\n",
    "        \n",
    "        \n",
    "        layers = []\n",
    "        latent_dim = 0\n",
    "        while in_size > 4:\n",
    "            layers.append(SequentialCouplingLayer((RealNVPLayer(in_channels, hidden_dim, num_blocks, batch_norm),)))\n",
    "            latent_dim += in_channels/2*in_size*in_size\n",
    "\n",
    "            in_size //= 2\n",
    "            in_channels *= 2 # Not 4 since we are going to split the channels in half to make the multi-scale architecture\n",
    "        \n",
    "        latent_dim += in_channels*in_size*in_size\n",
    "        layers.append(SequentialCouplingLayer(( AffineCouplingLayer(RealNVPCouplingFunction(in_channels, hidden_dim, num_blocks, batch_norm), SpatialCheckerboardChunker(permute=True)),\n",
    "                                                BatchNormCouplingLayer(in_channels),\n",
    "                                                AffineCouplingLayer(RealNVPCouplingFunction(in_channels, hidden_dim, num_blocks, batch_norm), SpatialCheckerboardChunker(permute=False)),\n",
    "                                                BatchNormCouplingLayer(in_channels),\n",
    "                                                AffineCouplingLayer(RealNVPCouplingFunction(in_channels, hidden_dim, num_blocks, batch_norm), SpatialCheckerboardChunker(permute=True)),\n",
    "                                                BatchNormCouplingLayer(in_channels)\n",
    "                                                )))\n",
    "        \n",
    "        self.z_initial_size = in_size\n",
    "        self.z_initial_channels = in_channels\n",
    "        print(\"LATENT DIM :\", latent_dim)\n",
    "        super().__init__(layers, int(latent_dim), latent_distribution, device)\n",
    "\n",
    "        #self.slcl = SoftLogCouplingLayer(tau=100)\n",
    "        self.lcl = LogitCouplingLayer()\n",
    "        apply_weight_norm(self)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Here we do the multi-scale architecture\n",
    "        batch_size = x.size(0)\n",
    "        z = []\n",
    "        log_det_jacobian = torch.zeros(batch_size, device=x.device)\n",
    "        x, ldj = self.lcl(x)\n",
    "        log_det_jacobian += ldj\n",
    "        for layer in self.layers[:-1]:\n",
    "            x, ldj = layer(x)\n",
    "            log_det_jacobian += ldj\n",
    "            z1, z2 = x.chunk(2, dim=1)\n",
    "            x = z2\n",
    "            z.append(z1.view(batch_size, -1))\n",
    "            \n",
    "        z_f, ldj = self.layers[-1](x)\n",
    "        log_det_jacobian += ldj\n",
    "        z.append(z_f.view(batch_size, -1))\n",
    "            \n",
    "        z = torch.cat(z, dim=1)\n",
    "        \n",
    "        #z, ldj = self.slcl(z)\n",
    "        #log_det_jacobian += ldj\n",
    "        \n",
    "        return z, log_det_jacobian\n",
    "    \n",
    "    def inverse(self, z):\n",
    "        batch_size = z.size(0)\n",
    "        \n",
    "        #z = self.slcl.inverse(z)\n",
    "\n",
    "        channels = self.z_initial_channels\n",
    "        size = self.z_initial_size\n",
    "        z_list = []\n",
    "        \n",
    "        for i in range(len(self.layers)):\n",
    "            \n",
    "            z_list.append(z[:, -channels*size*size:].view(batch_size, channels, size, size))\n",
    "            z = z[:, :-channels*size*size]\n",
    "            \n",
    "            if i == 0:\n",
    "                continue\n",
    "            channels //= 2\n",
    "            size *= 2\n",
    "        \n",
    "        h_L = self.layers[-1].inverse(z_list[0])\n",
    "        for i, layer in enumerate(reversed(self.layers[:-1])):\n",
    "            z_i = torch.cat((z_list[i+1], h_L),dim=1)\n",
    "            h_L = layer.inverse(z_i)\n",
    "        return self.lcl.inverse(h_L)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DequantizeAndRescale:\n",
    "    def __init__(self, noise_level=1/256, rescale_range=(0, 255), from_range=(0, 1)):\n",
    "        self.noise_level = noise_level\n",
    "        self.rescale_range = rescale_range\n",
    "        self.from_range = from_range\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = x.to(torch.float32)\n",
    "        noise = torch.rand_like(x) * self.noise_level\n",
    "        x = x + noise\n",
    "        \n",
    "        min_val, max_val = self.rescale_range\n",
    "        min_x, max_x = self.from_range\n",
    "        x = (x - min_x) / (max_x - min_x)\n",
    "        x = x * (max_val - min_val) + min_val\n",
    "        x = x.clamp(min_val, max_val)\n",
    "        return x\n",
    "\n",
    "class JustScale:\n",
    "    def __init__(self, s):\n",
    "        self.s = s\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        return sample * self.s\n",
    "    \n",
    "class ToDevice:\n",
    "    def __init__(self, device='cuda'):\n",
    "        super(ToDevice, self).__init__()\n",
    "        self.device = device\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return x.to(self.device)\n",
    "    \n",
    "class ToInt8Tensor:\n",
    "    def __init__(self):\n",
    "        super(ToInt8Tensor, self).__init__()\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        img_tensor = x * 255\n",
    "        img_tensor = img_tensor.to(torch.uint8)\n",
    "        return img_tensor\n",
    "\n",
    "class Normalize:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    def __call__(self, x): #should understand the batch dimension, mean is [3], x is [batch, 3, 64, 64]\n",
    "        mean = torch.tensor(self.mean).view(1, 3, 1, 1).to(x.device)\n",
    "        std = torch.tensor(self.std).view(1, 3, 1, 1).to(x.device)\n",
    "        return (x - mean) / std\n",
    "\n",
    "\n",
    "class Unnormalize:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    def __call__(self, x): #should understand the batch dimension, mean is [3], x is [batch, 3, 64, 64]\n",
    "        mean = torch.tensor(self.mean).view(1, 3, 1, 1).to(x.device)\n",
    "        std = torch.tensor(self.std).view(1, 3, 1, 1).to(x.device)\n",
    "        return x * std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_celeba = transforms.Compose([\n",
    "    transforms.CenterCrop(148),          \n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    DequantizeAndRescale(from_range=(0, 1), rescale_range=(0, 1-2/255)),\n",
    "])\n",
    "\n",
    "transforms_celeba_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  \n",
    "    transforms_celeba\n",
    "])\n",
    "\n",
    "batch_size = 64 \n",
    "\n",
    "celeba_dataset = torchvision.datasets.CelebA(root='./data', split='train', download=False, transform=transforms_celeba_train)\n",
    "celeba_val_dataset = torchvision.datasets.CelebA(root='./data', split='valid', download=False, transform=transforms_celeba)\n",
    "celeba_test_dataset = torchvision.datasets.CelebA(root='./data', split='test', download=False, transform=transforms_celeba)\n",
    "\n",
    "celeba_loader = DataLoader(dataset=celeba_dataset, batch_size=batch_size, shuffle=True, num_workers=4, worker_init_fn=lambda worker_id: np.random.seed(seed + worker_id))\n",
    "celeba_val_loader = DataLoader(dataset=celeba_val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "celeba_test_loader = DataLoader(dataset=celeba_test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a grid of images nrow x nrow\n",
    "def make_grid(images, nrow=8):\n",
    "    images = images.detach().cpu()\n",
    "    grid = torchvision.utils.make_grid(images, nrow=nrow)\n",
    "    return grid.permute(1, 2, 0)\n",
    "\n",
    "def show(img):\n",
    "    img = img.detach().cpu()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "def show_images(images, nrow=8):\n",
    "    grid = make_grid(images, nrow)\n",
    "    show(grid)\n",
    "\n",
    "# plot the first 64 images\n",
    "images, _ = next(iter(celeba_val_loader))\n",
    "img = images[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use images of size 64x64 with 3 channels\n",
    "in_channels = 3\n",
    "hidden_channels = 32\n",
    "num_blocks = 2\n",
    "batch_norm = True\n",
    "size = 64\n",
    "latent_distribution = torch.distributions.Normal(0, 1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "realnvp = MultiScaleRealNVP(size, in_channels, hidden_channels, num_blocks, latent_distribution, device=device, batch_norm=batch_norm)\n",
    "realnvp.eval()\n",
    "#print the number of parameters\n",
    "print(sum(p.numel() for p in realnvp.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples from the learned model\n",
    "with torch.no_grad():\n",
    "    learned_samples = realnvp.sample(batch_size).cpu()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "images, _ = next(iter(celeba_val_loader))\n",
    "show_images(images)\n",
    "plt.title(\"Validation samples\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "show_images(learned_samples)\n",
    "plt.title(\"Generated samples\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Training parameters\n",
    "optimizer = torch.optim.AdamW(realnvp.parameters(), lr=1e-4)\n",
    "n_epochs = 5000\n",
    "\n",
    "# Store losses to plot\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# TensorBoard Summary Writer\n",
    "writer = SummaryWriter(log_dir='runs/celebA')\n",
    "s = 0\n",
    "\n",
    "def plot_generated_samples(samples, epoch):\n",
    "    samples = samples.permute(0, 2, 3, 1).cpu().numpy()\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow((samples[i] - samples[i].min()) / (samples[i].max() - samples[i].min()))\n",
    "        ax.axis('off')\n",
    "    plt.suptitle(f'Generated Samples at Epoch {epoch}')\n",
    "    plt.show()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    batch_losses = []\n",
    "\n",
    "    # Training phase\n",
    "    realnvp.train()\n",
    "    for i, (batch_samples, _) in enumerate(celeba_loader):\n",
    "        print(f\"{i}/{len(celeba_loader)}\", end='\\r')\n",
    "        batch_samples = batch_samples.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        z, log_prob = realnvp.forward_log_prob(batch_samples)\n",
    "        loss = -torch.mean(log_prob)  # Maximum likelihood estimation\n",
    "        \n",
    "        # Log Z statistics\n",
    "        z_stats = {\n",
    "            'z_max': z.max().item(),\n",
    "            'z_min': z.min().item(),\n",
    "            'z_mean': z.mean().item(),\n",
    "            'z_std': z.std().item(),\n",
    "            'z_percent_nan': torch.isnan(z).sum().item() / z.numel()\n",
    "        }\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_losses.append(loss.item())\n",
    "        writer.add_scalar('Loss/train_b', loss.item(), s)\n",
    "\n",
    "        # Log Z statistics to TensorBoard\n",
    "        for stat_name, value in z_stats.items():\n",
    "            writer.add_scalar(f'Statistics/{stat_name}', value, s)\n",
    "\n",
    "        # Intermediate logging and plotting\n",
    "        if s % (len(celeba_loader) // 4) == 0:\n",
    "            realnvp.eval()\n",
    "            with torch.no_grad():\n",
    "                learned_samples = realnvp.sample(batch_size).cpu()\n",
    "                writer.add_images('b/Generated Samples', learned_samples, s)\n",
    "                \n",
    "                # Log X statistics\n",
    "                x_stats = {\n",
    "                    'x_max': learned_samples.max().item(),\n",
    "                    'x_min': learned_samples.min().item(),\n",
    "                    'x_mean': learned_samples.mean().item(),\n",
    "                    'x_std': learned_samples.std().item()\n",
    "                }\n",
    "                for stat_name, value in x_stats.items():\n",
    "                    writer.add_scalar(f'Statistics/{stat_name}', value, s)\n",
    "                \n",
    "                # Log scaling factors\n",
    "                scaling_factors = get_scaling_factor_histogram(realnvp)\n",
    "                writer.add_histogram('Statistics/Scaling_Factors', torch.tensor(scaling_factors), s)\n",
    "                \n",
    "                # Plot generated samples\n",
    "                plot_generated_samples(learned_samples, epoch)\n",
    "                \n",
    "            realnvp.train()\n",
    "\n",
    "        s += 1\n",
    "\n",
    "    # Validation phase\n",
    "    realnvp.eval()\n",
    "    batch_val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for val_samples, _ in celeba_val_loader:\n",
    "            val_samples = val_samples.to(device)\n",
    "            val_loss = -torch.mean(realnvp.log_prob(val_samples))\n",
    "            batch_val_losses.append(val_loss.item())\n",
    "\n",
    "        avg_train_loss = np.mean(batch_losses)\n",
    "        avg_val_loss = np.mean(batch_val_losses)\n",
    "        \n",
    "        print(f\"Epoch {epoch} - Training loss: {avg_train_loss:.4f} - Validation loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # TensorBoard Logging\n",
    "        writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
    "        writer.add_scalar('Loss/val', avg_val_loss, epoch)\n",
    "\n",
    "    # Append losses for plotting\n",
    "    val_losses.append(avg_val_loss)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "# Close the writer after training\n",
    "writer.close()\n",
    "\n",
    "print('Training completed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results in epoch0.png and epoch48.png**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classic_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
